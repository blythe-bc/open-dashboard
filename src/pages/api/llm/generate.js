import { openDb } from '../../../lib/db';
import crypto from 'crypto';

export default async function handler(req, res) {
    if (req.method !== 'POST') {
        return res.status(405).json({ message: 'Method Not Allowed' });
    }

    const { dashboardId, context, prompt } = req.body;
    const db = await openDb();
    const userId = req.headers['x-auth-user'] || 'DOMAIN\guest';

    try {
        // 1. Check Policy
        const dashboard = await db.get(`SELECT * FROM Dashboard WHERE id = ?`, [dashboardId]);
        if (!dashboard) return res.status(404).json({ message: 'Dashboard not found' });

        const policy = await db.get(`SELECT * FROM WorkspacePolicy WHERE workspaceId = ?`, [dashboard.workspaceId]);
        if (!policy || !policy.llmEnabled) {
            return res.status(403).json({ message: 'LLM features are disabled for this workspace' });
        }

        // 2. Audit Log
        await db.run(
            `INSERT INTO AuditLog (id, event, user, details) VALUES (?, ?, ?, ?)`,
            [
                crypto.randomUUID(),
                'LLM_REQUEST',
                userId,
                JSON.stringify({ dashboardId, promptLength: prompt?.length })
            ]
        );

        // 3. Call LLM (Mocked)
        // In real impl, fetch('http://localhost:1234/v1/chat/completions', ...)
        
        await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate latency

        const mockResponse = `
Here is a summary of your dashboard data:
- Based on the context provided, there are ${context?.widgets?.length || 0} widgets.
- The data indicates positive trends in Sales.
- Recommendation: Drill down into Region 'US' for more details.
(Generated by Local LLM)
        `;

        res.status(200).json({ result: mockResponse });

    } catch (error) {
        console.error(error);
        res.status(500).json({ error: error.message });
    } finally {
        await db.close();
    }
}
